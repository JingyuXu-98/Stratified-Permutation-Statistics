%% Template for the submission to:
%%   Bernoulli [BJ]
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% In this template, the places where you   %%
%% need to fill in your information are     %%
%% indicated by '???'.                      %%
%%                                          %%
%% Please do not use \input{...} to include %%
%% other tex files. Submit your LaTeX       %%
%% manuscript as one .tex document.         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\documentclass[bj,numbers]{imsart}% uncomment this for numbers citation
\documentclass[bj,authoryear]{imsart}

%% Packages
% \usepackage{}
\usepackage{apalike}

\usepackage{booktabs}
\usepackage{multirow}

\startlocaldefs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Uncomment next line to change            %%
%% the type of equation numbering           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\numberwithin{equation}{section}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Axiom, Claim, Corollary, Hypothesis, %%
%% Lemma, Theorem, Proposition              %%
%% use \theoremstyle{plain}                 %%
\theoremstyle{plain}
\newtheorem{theo}{Theorem}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{lem}{Lemma}[section]
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\theoremstyle{plain}
%\newtheorem{???}{???}
%\newtheorem*{???}{???}
%\newtheorem{???}{???}[???]
%\newtheorem{???}[???]{???}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Assumption, Definition, Example,     %%
%% Notation, Property, Remark, Fact         %%
%% use \theoremstyle{definition}            %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\theoremstyle{definition}
%\newtheorem{???}{???}
%\newtheorem*{???}{???}
%\newtheorem{???}{???}[???]
%\newtheorem{???}[???]{???}
\theoremstyle{definition}
\newtheorem{defi}{Definition}[section]
\newtheorem{exam}{Example}[section]
\newtheorem{coro}{Corollary}[section]
\newtheorem{remark}{Remark}
\newtheorem{condi}{Condition}[section]
\newtheorem{assu}{Assumption}[section]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please put your definitions here:      
\newcommand{\e}{\mathbb{E}}
\newcommand{\va}{\mathrm{Var}}
\newcommand{\p}{\mathbb{P}}%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endlocaldefs

\begin{document}

\begin{frontmatter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Cram\'{e}r-type moderate deviation for general self-normalized non-linear statistics}
%\title{A sample article title with some additional note\thanksref{T1}}
\runtitle{Cram\'{e}r-type moderate deviation for double index permutation statistics}
%\thankstext{T1}{A sample of additional note to the title.}

\begin{aug}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ORCID can be inserted by command:         %%
%% \orcid{0000-0000-0000-0000}               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author[A]{\inits{SH Liu}\fnms{Song-hao}~\snm{Liu}\ead[label=e1]{liusonghao@dlut.edu.cn}}
\author[B]{\inits{QM Shao}\fnms{Qi-man}~\snm{Shao}\ead[label=e2]{shaoqm@sustech.edu.cn}}
\author[B]{\inits{JY Xu}\fnms{Jing-yu}~\snm{Xu}\ead[label=e3]{12131253@mail.sustech.edu.cn}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Addresses                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\address[A]{School of Mathematical Sciences, Dalian University of Technology, Dalian, Liaoning, China\printead[presep={,\ }]{e1}}
\address[B]{Department of Statistics and Data Science, Shenzhen International Center for Mathematics, Southern University of Science and Technology, Shenzhen, Guangdong, 518055, China\printead[presep={,\ }]{e2}}
\address[B]{Department of Statistics and Data Science, Southern University of Science and Technology, Shenzhen, Guangdong, 518055, China\printead[presep={,\ }]{e3}}
\end{aug}

\begin{abstract}
Let $\{(X_i,Y_i)\}_{i = 1}^{n}$ be a sequence of independent bivariate random vectors. In this paper we establish a Cram\'{e}r-type moderate deviation theorem for general self-normalized non-linear statistics $(\sum_{i = 1}^{n}X_i + D_{1n})/(\sum_{i = 1}^{n}Y_i^2(1+D_{2n}))^{1/2}$
\end{abstract}

\begin{keyword}
\kwd{Cram\'{e}r-type moderate deviation}
\kwd{Stein's Method}
\end{keyword}

\end{frontmatter}
\section{Introduction}
In this paper, we aim to prove a Cram\'{e}r-type moderate deviation for general non-linear statistics \dots

\section{Main Results}
Let $(X_1,Y_1),(X_2,Y_2),\dots,(X_n,Y_n)$ be independent bivariate random vectors, and for convenience presentation satisfying
\begin{align}
    \mathbb{E} X_i = 0\   \text{for}\  i\geq 1 \quad \text{and} \quad  \sum_{i=1}^{n}\mathbb{E} X_{i}^{2} = 1 = \sum_{i=1}^{n}\mathbb{E} Y_{i}^{2}\notag
\end{align}
Let
\begin{center}
    $S_n = \sum_{i=1}^{n}X_i$, $V_{n}^{2} = \sum_{i=1}^{n}Y_{i}^{2}$ and $T_n = \frac{S_n+D_{1n}}{V_n(1+D_{2n})^{\frac{1}{2}}}$
\end{center}
Where  $D_{1n} = D_{1n}(X_1,\dots,X_n,Y_1,\dots,Y_n)$ is a measurable function of $\{X_i\}_{i=1}^{n}$ and $\{Y_i\}_{i=1}^{n}$ and $D_{2n}$ is also a measurable function of $\{X_i\}_{i=1}^{n}$ and $\{Y_i\}_{i=1}^{n}$. To ensure that $T_n$ is well defined, it is assumed that $1+D_{2n}>0$.
\begin{theo}\label{theo-cramer-moderate-deviation-for-general-self-norm-non-linear}
  Suppose there exits some constants $c_0>0$ such that for $x>0$ satisfying $$\mathbb{E} e^{min\{\frac{X_i^2}{Y_i^2+c_0\mathbb{E} Y_i^2},2xX_i\}}<\infty$$ and we assume $\mathbb{E} |X_i|^3<\infty$ and $\mathbb{E} |Y_i|^3<\infty$ for $i\geq 1$. Then there exist absolute positive constants $0<c_1\leq \frac{1}{25}$ and $A>0$ such that
  \begin{equation}
    \begin{aligned}
      P(T_n\geq x)\leq&[1-\Phi(x)]\Psi_{x}^{*}e^{O_1R_x}(1+O_2(1+x)L_{3,n}+O_3Q_{n,x})\\
      &+P(|D_{1n}|> V_n/4x)+P(|D_{2n}|>1/4x^2)
    \end{aligned}
  \end{equation}
  \begin{equation}
    P(T_n\geq x)\geq \Psi_{x}^{*}e^{-O_4R_x}[1-\Phi(x)](1-O_5(1+x)L_{3,n}-O_6Q_{n,x})
  \end{equation}
  where
  $$\Psi_{x}^{*} = \exp\{\frac{x^3}{6}\sum_{i=1}^{n}EX_i^3-\frac{x^3}{2}\sum_{i=1}^{n}EX_iY_i^2\}$$
  $$L_{3,n} = \sum_{i=1}^{n}(\mathbb{E} |X_i|^3+\mathbb{E}|Y_i|^3)$$
  \begin{equation}
    \begin{aligned}
      \delta_{x,i} =& (1+x)^3\left(\mathbb{E} [|X_i|^31\{|(1+x)X_i|>1\}]+\mathbb{E} [|Y_i|^31\{|(1+x)Y_i|>1\}]\right)\\
      &+(1+x)^4\left(\mathbb{E} [|X_i|^41\{|(1+x)X_i|\leq1\}]+\mathbb{E} [|Y_i|^41\{|(1+x)Y_i|\leq1\}]\right)
    \end{aligned}
  \end{equation}
  $$r_{x,i} = \mathbb{E}[\exp\{\min(\frac{X_i^2}{Y_i^2+c_0\mathbb{E} Y_i^2},2xX_i)\}1\{|(1+x)X_i|>1\}]$$
  $$R_{x,i} = \delta_{x,i}+r_{x,i}, \ \delta_x = \sum_{i=1}^{n}\delta_{x,i},\ r_x = \sum_{i=1}^{n}r_{x,i},\ R_x = \delta_x+r_x$$
  for all $x>0$ satisfying 
  \begin{equation}
    (1+x)L_{3,n}\leq c_1,\ \ x^{-2}R_x\leq c_1,\label{L3n-and-Rx-bound}
  \end{equation}
  \begin{equation}
    x\leq \frac{\frac{1}{4}\land \frac{1}{2\sqrt{c_0}}}{[\max_i(\mathbb{E} |X_i|^3+\mathbb{E} |Y_i|^3)]^{1/3}}, \ \ \max_ir_{x,i}\leq c_1,\label{x-and-rxi-bound}
  \end{equation}
  where $|O_i|\leq A, i=1,\dots,6$
\end{theo}


\section{Proofs}

\begin{proof}[Proof of Theorem \ref{theo-cramer-moderate-deviation-for-general-self-norm-non-linear}]
Since $(1+D_{2n})^{\frac{1}{2}}\geq 1+\min(D_{2n}, 0)$, and the elementary inequality:
\begin{equation}
  1+s/2-s^2/2\leq (1+s)^{\frac{1}{2}}\leq 1+s/2,\quad s\geq -1
\end{equation}
Let $s = V_{n}^{2}-1$, then we have 
\begin{equation}
  (1+V_{n}^{2})/2-(v_{n}^{2}-1)^2/2\leq V_n\leq 1+(V_{n}^{2}-1)/2
\end{equation}
Which leads to
\begin{equation}
  \begin{aligned}
    V_n(1+D_{2n})^{\frac{1}{2}}& \geq V_n+V_n \min(D_{2n}, 0)\\
    &\geq (1+V_{n}^{2})/2-(V_{n}^{2}-1)^2/2+(1+(V_{n}^{2}-1)/2)\min(D_{2n}, 0)\\
    &\geq (1+V_{n}^{2})/2-(V_{n}^{2}-1)^2+\min(D_{2n}, 0)
  \end{aligned}
\end{equation}
% the last inequality of above since D_{2n} > -1
Using inequality $2ab\leq a^2+b^2$ yields the reverse inequality
\begin{equation}
  V_{n}(1+D_{2n})^{\frac{1}{2}}\leq V_{n}^{2}/2+(1+D_{2n})/2
\end{equation}
consequantly, for any $x>0$
\begin{align}\label{biggerset}
  \{T_n\geq x\}& = \{S_n+D_{1n}\geq xV_n(1+D_{2n})^{1/2}\}\notag\\
  &\subseteq \{S_n+D_{1n}\geq x((1+V_{n}^{2})/2-(V_{n}^{2}-1)^2+\min(D_{2n},0))\}\notag\\
  &= \{xS_n-x^2V_{n}^{2}/2\geq x^2/2-x[x(V_{n}^{2}-1)^2+D_{1n}-x\min(D_{2n},0)]\},
\end{align}
and 
\begin{align}
  \{T_n\geq x\}\supseteq\{xS_n-x^2V_{n}^{2}/2\geq x^2/2+x[xD_{2n}/2-D_{1n}]\}.\label{smallset}
\end{align}
We proof the theorem for two scenarios $0<x\leq 1$ and $x>1$, respectively. For $0<x \leq 1$, it is sufficient to prove a Berry-Esseen bound.

\begin{prop}\label{prop-0-x-1-Berry-Esseen}
  dd
\end{prop}

Then by (\ref{biggerset}), we have for $x\geq 1$
\begin{equation}
  \begin{aligned}
    P(T_n\geq x)& = P(\frac{S_n+D_{1n}}{V_n(1+D_{2n})^{\frac{1}{2}}}\geq x)\\
    &\leq P(S_n\geq xV_n(1+\min(D_{2n},0))-D_{1n})\\
    &\leq P(S_n\geq xV_n(1+\min(D_{2n},0))-D_{1n},|D_{1n}|\leq \frac{V_n}{4x},|D_{2n}|\leq \frac{1}{4x^2})\\
    &\ \ \ \ +P(\frac{|D_{1n}|}{V_n}> \frac{1}{4x})+P(|D_{2n}|>\frac{1}{4x^2})\\
    &\leq P(S_n\geq xV_n(1+\min(D_{2n},0))-D_{1n},|D_{1n}|\leq \frac{V_n}{4x},|D_{2n}|\leq \frac{1}{4x^2},|V_{n}^{2}-1|\leq \frac{1}{2x})\\
    &\ \ \ \ +P(S_n\geq xV_n(1+\min(D_{2n},0))-D_{1n},|D_{1n}|\leq \frac{V_n}{4x},|D_{2n}|\leq \frac{1}{4x^2},|V_{n}^{2}-1|> \frac{1}{2x})\\
    &\ \ \ \ +P(\frac{|D_{1n}|}{V_n}> \frac{1}{4x})+P(|D_{2n}|>\frac{1}{4x^2})\\
    &\leq P(xS_n-x^2V_{n}^{2}/2\geq x^2/2-x\Delta_{1n})+P(S_n\geq (x-1/2x)V_n,|V_{n}^{2}-1|>1/2x)\\
    &\ \ \ \ +P(\frac{|D_{1n}|}{V_n}> \frac{1}{4x})+P(|D_{2n}|>\frac{1}{4x^2}),
  \end{aligned}
\end{equation}
% 细节后面补充一下，上面这个不等式的结果
where
% 这里\Delta1n直接给放缩掉,然后证明就会比较容易(模仿高蓝的证明),\Delta2n的时候没办法还是会出现非常麻烦的项,类似于周文心文章中的R项。
\begin{equation}
  % \Delta_{1n} = \min\{x(V_{n}^{2}-1)^2+|D_{1n}|-x\min(D_{2n},0),\frac{1}{x}\}>0,
  \Delta_{1n} = \min\{x(V_{n}^{2}-1)^2+\frac{1}{2x}+\frac{1}{16x^2},\frac{1}{x}\}>0,
\end{equation}
by\eqref{smallset}, we have
\begin{align}
  P(T_n\geq x )\geq P(xS_n-x^2V_{n}^{2}/2\geq x^2/2+x\Delta_{2n}),
\end{align}
where
\begin{align}
  \Delta_{2n} = xD_{2n}/2-D_{1n}.
\end{align}
If we want to have a upper and lower bound of $P(T_n\geq x)$ then we need to proof the following three propositions.

\begin{prop}\label{proposition A1}
There exits positive absolute constants  
\begin{align}
  P(xS_n-x^2V_{n}^{2}/2\geq x^2/2-x\Delta_{1n}) \leq  \Psi_{x}^{*}[1-\Phi(x)]e^{A_1R_x}(1+A_2(1+x)L_{3,n}+A_3Q_{n,x}).
\end{align} 
for $x>1$ satisfying (\ref{L3n-and-Rx-bound}) and (\ref{x-and-rxi-bound}), where $|O_1| \leq A$ and $|O_{1}|\leq A$
\end{prop}

\begin{prop}\label{proposition A2}
There exits positive absolute constants  
\begin{align}
  P(S_n\geq (x-1/2x)V_n,|V_{n}^{2}-1|>1/2x)\leq AR_x[1-\Phi(x)]\Psi_{x}^{*}e^{AR_x}.
\end{align}
for $x>1$ satisfying (\ref{L3n-and-Rx-bound}) and (\ref{x-and-rxi-bound}), where $|O_1| \leq A$ and $|O_{1}|\leq A$
\end{prop}

\begin{prop}\label{proposition B1}
There exists positive absolute constants  
\begin{align}
  P(xS_n-x^2V_{n}^{2}/2\geq x^2/2+x\Delta_{2n})\geq \Psi_{x}^{*}e^{-A_2R_x}[1-\Phi(x)](1-O_2(1+x)L_{3,n}-O_3Q_{n,x}).
\end{align}
for $x>1$ satisfying (\ref{L3n-and-Rx-bound}) and (\ref{x-and-rxi-bound}), where $|O_1| \leq A$ and $|O_{1}|\leq A$
\end{prop}

\end{proof}





\begin{proof}[Proof of Proposition \ref{proposition A1}]
We firstly give some notations related to conjugated method, which is the main tool to prove Proposition \ref{proposition A1}--\ref{proposition B1}. 
For $1\leq i \leq n$, let
\begin{align}
  W_i = 2xX_i-x^2Y_{i}^{2},\notag
\end{align}
and let $(\xi_i,\eta_i)$ be independent random vectors with distribution
\begin{align}
  V_i(x,y) = \frac{\mathbb{E}\{e^{\lambda W_i}1(X_i\leq x,Y_i\leq y)\}}{\mathbb{E} e^{\lambda W_i}}.\label{change-of-measure-distribution}
\end{align}
Denote 
\begin{align}
  \tilde{W}_i = 2x\xi_i-x^2\eta_i^2,\notag
\end{align}
then we have
\begin{align}
  \mathbb{E} \tilde{W}_i &= \frac{\mathbb{E} W_ie^{\lambda W_i}}{\mathbb{E} e^{\lambda W_i}}\notag\\
  Var\tilde{W}_i& = \frac{\mathbb{E} W_{i}^{2}e^{\lambda W_i}}{\mathbb{E} e^{\lambda W_i}}-(\mathbb{E} \tilde{W}_i)^2\notag\\
  \mathbb{E}|\tilde{W}_i|^3 &= \frac{\mathbb{E}|W_i|^3e^{\lambda W_i}}{\mathbb{E} e^{\lambda W_i}},\notag
\end{align}
then we give the expansion of the above moments. Next two lemmas are Lemma A.1 and A.2 of \cite{gao2022refined})

\begin{lem}\label{lem-expansion-mgf}
For $\frac{1}{4}\leq \lambda\leq \frac{1}{4}$ and $x>0$ satisfying (\ref{x-and-rxi-bound}), there exits an absolute constant $A$ such that 
\begin{align}
  Ee^{\lambda W_i} &= 1+2\lambda^2x^2EX_i^2-\lambda x^2EY_i^2+\frac{4}{3}\lambda^3x^3EX_i^3-2\lambda^2 x^3EX_iY_i^2+O_1R_{x,i}\notag\\
  & = \exp\{2\lambda^2x^2EX_i^2-\lambda x^2EY_i^2+\frac{4}{3}\lambda^3x^3EX_i^3-2\lambda^2 x^3EX_iY_i^2+O_1R_{x,i}\}\\
  EW_ie^{\lambda W_i}& = 4\lambda x^2EX_i^2-x^2EY_i^2+4\lambda^2x^3EX_i^3-4\lambda x^3EX_iY_i^2+O_3R_{x,i}\\
  EW_i^2e^{\lambda W_i}& = 4x^2EX_i^2+8\lambda x^3EX_i^3-4x^3EX_iY_i^3+O_4R_{x,i}\\
  E|W_i|^3e^{\lambda W_i}& = O_5x^3(E|X_i|^3+E|Y_i|^3)+O_6R_{x,i}
\end{align}
Where $|O_i|\leq A$ for $i=1,\dots,6$.
\end{lem}

\begin{lem}\label{lem-X-Y-moment-upper-bound}
We have for $x$ satisfying (\ref{x-and-rxi-bound}) that
\begin{align}
  (1+x)^4(EX_i^2)^2&\leq 2\delta_{x,i}\notag\\
  (1+x)^5EX_i^2E|X_i|^3&\leq 2\delta_{x,i}\notag\\
  (1+x)^6(E|X_i|^3)^2&\leq \delta_{x,i},\notag
\end{align}
and similar results hod for $Y_i$. in addition if $x$ also satisfies (\ref{L3n-and-Rx-bound}), then 
\begin{align}
  (1+x)^4L_{3,n}^2\leq 2\delta_x\notag.
\end{align}
\end{lem}
By lemmas \ref{lem-expansion-mgf} and \ref{lem-X-Y-moment-upper-bound}, we can have under condition (\ref{x-and-rxi-bound}),
\begin{align}
  \mathbb{E} \tilde{W}_i &= x^2\left(4\lambda\mathbb{E}X_i^2-\mathbb{E}Y_i^2\right)+x^3\left(4\lambda\mathbb{E}X_i^3-4\lambda\mathbb{E}X_iY_i^2\right) + O_1R_{x,i},\notag\\
  \text{Var}\tilde{W}_i& = 4x^2\mathbb{E}X_i^2+x^3\left(8\lambda \mathbb{E}X_i^3-4\mathbb{E}X_iY_i^2\right)+O_2R_{x,i},\notag\\
  \mathbb{E}|\tilde{W}_i|^3 &= O_3x^3\left(\mathbb{E}|X_i|^3+\mathbb{E}|Y_i|^3\right)+O_4R_{x,i}.\notag
\end{align}
Let $m_n = \sum_{i=1}^{n}\mathbb{E} \tilde{W_i}$, $\sigma_n = \sqrt{\sum_{i=1}^{n}Var(\tilde{W}_i)}$, $\nu_n = \sum_{i=1}^{n}\mathbb{E} |\tilde{W}_i|^3$. Then we can have:
\begin{align}
  m_n = &  (4\lambda -1)x^2+x^3\left(4\lambda^2\sum_{i=1}^{n}EX_i^3-4\lambda\sum_{i=1}^{n}EX_iY_i^2\right)+O_1R_x,\label{m_n}\\
  \sigma_n^2 = & 4x^2+x^3\left(8\lambda\sum_{i=1}^{n}EX_i^3-4\sum_{i=1}^{n}EX_iY_i^2\right)+O_2R_x,\label{sigma_n}\\
  \nu_n = &  O_3x^3L_{3,n}+O_4R_x.\label{nu_n}
\end{align}
Define $m(\lambda) = \sum_{i=1}^{n}\log\mathbb{E} e^{\lambda W_i}$, $\tilde{S}_n = \sum_{i = 1}^{n}\tilde{W}_i$, $U_n = \left(\tilde{S}_n - m_n\right)/\sigma_n$, therefore $m_n = m^{\prime}(\lambda)$, and $\sigma_{n}^{2} = m^{\prime\prime}(\lambda)$. We can obtain a lemma, which can be directly obtained through Lemma A.3 in \cite{gao2022refined}.

\begin{lem}\label{lem-solution-lambda}
For x satisfying (\ref{L3n-and-Rx-bound}) and (\ref{x-and-rxi-bound}), then the equation
\begin{align}
  m^{\prime}(\lambda) = x^2,\notag
\end{align}
has a unique solution $\lambda_1$, in addition, $\lambda_1$ satisfies $\frac{1}{4}<\lambda_1<\frac{3}{4}$ and 
\begin{align}
  \left|\lambda_1 - \frac{1}{2} + x\left(\lambda_1^2\sum_{i = 1}^{n}\mathbb{E}X_{i}^{3}-\lambda_1\sum_{i = 1}^{n}\mathbb{E}X_{i}Y_{i}^{2}\right)\right|\leq Ax^{-2}R_{x},\label{lambda-1}
\end{align}
and 
\begin{align}
  m(\lambda_1) = (2\lambda_{1}^{2}-\lambda_1)x^2+x^3\left(\frac{4}{3}\lambda_{1}^{3}\sum_{i = 1}^{n}\mathbb{E}X_{i}^{3}-2\lambda_{1}^{2}\sum_{i = 1}^{n}\mathbb{E}X_{i}Y_{i}^{2}\right)+O_1R_{x}.\label{m-lambda-1}
\end{align}
\end{lem}
Now, we can proof the proposition \ref{proposition A1}, by definiton of $W_i$ we have
\begin{align}
  P(xS_n-x^2V_{n}^{2}/2\geq x^2/2-x\Delta_{1n}) = & P\left(\sum_{i=1}^{n}(2xX_i-x^2Y_{i}^{2})\geq x^2-2x\Delta_{1n}\right)= P\left(\sum_{i = 1}^{n}W_i \geq x^2-2\Delta_{1n}\right). \notag
\end{align}
Assume $\lambda_1$ is the solution to $m^{\prime}(\lambda) = m_n = x^2$, by the conjugate method
\begin{align}
  &P\left(\sum_{i=1}^{n}W_i\geq x^2-2x\Delta_{1n}\right)\notag\\
  =&\mathbb{E}\left(e^{\lambda_1\sum_{i=1}^{n}W_i}\right)\mathbb{E}\left(e^{-\lambda_1 \sum_{i=1}^{n}\tilde{W}_i}{\bf 1}\left\{\sum_{i=1}^{n}\tilde{W}_i\geq x^2-2x\tilde{\Delta}_{1n}\right\}\right)\notag\\
  =&\exp(m(\lambda_1))\mathbb{E} e^{-\lambda_1(\frac{\tilde{S}_n-m_n+m_n}{\sigma_n})\sigma_n}{\bf 1}\left\{\frac{\tilde{S}_n-m_n}{\sigma_n}\geq -\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\right\}\notag\\
  =&\exp(m(\lambda_1))\mathbb{E} e^{-\lambda_1(\sigma_n U_n+m_n)}{\bf 1}\left\{U_n\geq -\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\right\}\notag\\
  \leq &\exp(m(\lambda_1)-\lambda_1m_n)\mathbb{E} \left(e^{-\lambda_1\sigma_nU_n}{\bf 1}\{U_n\geq 0\}\right)\notag\\
  &+\exp(m(\lambda_1)-\lambda_1m_n)\mathbb{E} \left(e^{-\lambda_1\sigma_n U_n}{\bf 1}\{0\geq U_n\geq -\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\}\right)\notag\\
  :=&H_1+H_2
\end{align}
where $\tilde{\Delta}_{1n} = \min\{x(\sum_{i = 1}^{n}\eta_{i}^{2}-1)^2 + |\tilde{D}_{1n}| - x\min(\tilde{D}_{2n},0),1/x\}$. Let $G_n(t)$ is the distribution of $U_n$, then we have 
\begin{align}
  H_1 =& \exp(m(\lambda_1)-\lambda_1x^2)\int_{0}^{+\infty}e^{-\lambda_{1}\sigma_{n}t}\,dG_n(t)\notag\\
  =& \exp(m(\lambda_1)-\lambda_1x^2)\int_{0}^{+\infty}e^{-\lambda_{1}\sigma_{n}t}\,d(G_n(t) - \Phi(t))\notag\\
  &+\exp(m(\lambda_1)-\lambda_1x^2)\int_{0}^{+\infty}e^{-\lambda_{1}\sigma_{n}t}\,d\Phi(t)\notag\\
  :=&J_1+J_2
\end{align}
by integral by parts, we have
\begin{align}
  J_{1} = &\exp(m(\lambda_1)-\lambda_1x^2)\int_{0}^{+\infty}e^{-\lambda_{1}\sigma_{n}t}\,d(G_n(t) - \Phi(t))\notag\\
  \leq& 2\exp(m(\lambda_1)-\lambda_1x^2)\sup_{z\in R}|P(U_n\leq z)-\Phi(z)|.\notag
\end{align}
Applying the Berry-Esseen theorem to $\sup_{z\in R}|P(U_n\leq z)-\Phi(z)|$, and by (\ref{sigma_n}) and (\ref{nu_n}), we can find that for $x>1$ satisfying (\ref{L3n-and-Rx-bound}),
\begin{align}
  \sup_{z\in R}|P(U_n\leq z)-\Phi(z)| \leq A\nu_n\sigma_{n}^{-3} \leq A(L_{3,n}+x^{-3}R_x).\label{Un-berry-esseen-bound}
\end{align}
By applying (\ref{lambda-1}) and (\ref{m-lambda-1}) in Lemma \ref{lem-solution-lambda} we have
\begin{align}
  |\lambda_1 - 1/2| \leq A_{1}xL_{3,n} + A_{2}x^{-2}R_{x},\notag
\end{align}
and by Lemma \ref{lem-X-Y-moment-upper-bound} we have $x^4L_{3,n}^{2}\leq 2\delta_{x}<2R_{x}$, we obtain for x satisfying (\ref{L3n-and-Rx-bound}) and (\ref{x-and-rxi-bound}) that 
\begin{align}
  (2\lambda_{1}^{2}-\lambda_{1})x^2+\frac{1}{2}x^2-\lambda_{1}x^2 = 2x^2(\lambda_{1}-\frac{1}{2})^2\leq O_{1}R_{x},\notag
\end{align}
Then,by (\ref{m-lambda-1}) we have
\begin{align}
  &m(\lambda_{1})+\frac{1}{2}x^2-\lambda_{1}x^2\notag\\
  = & (2\lambda_{1}^{2}-\lambda_1)x^2 + \frac{1}{2}x^2 -\lambda_{1}x^2 +x^3\left(\frac{4}{3}\lambda_{1}^{3}\sum_{i = 1}^{n}\mathbb{E}X_{i}^{3}-2\lambda_{1}^{2}\sum_{i = 1}^{n}\mathbb{E}X_{i}Y_{i}^{2}\right)+O_1R_{x}\notag\\
  \leq & x^3\left(\frac{1}{6}\sum_{i = 1}^{n}\mathbb{E}X_{i}^{3}-\frac{1}{2}\sum_{i = 1}^{n}\mathbb{E}X_{i}Y_{i}^{2}\right)+ 8x^3|\lambda_{1}-1/2|L_{3,n}+O_1R_{x}\notag\\
  \leq & x^3\left(\frac{1}{6}\sum_{i = 1}^{n}\mathbb{E}X_{i}^{3}-\frac{1}{2}\sum_{i = 1}^{n}\mathbb{E}X_{i}Y_{i}^{2}\right)+O_1R_{x},\label{mlambda1+x^2/2-lambda1x^2}
\end{align}
and since for $x>1$ we have
\begin{align}
  e^{-\frac{x^2}{2}} \leq 4x[1-\Phi(x)],\label{exp(-x^2/2)-leq-1-phi-bound}
\end{align}
we can obtain
\begin{align}
  J_{1} \leq &  2A\exp(m(\lambda_1)-\lambda_1x^2)(L_{3,n}+x^{-3}R_x)\notag\\
  \leq & 2A\exp(m(\lambda_1) +\frac{1}{2}x^2-\lambda_1x^2)\exp(-x^2/2)(L_{3,n}+x^{-3}R_x)\notag\\
  \leq &[1-\Phi(x)]\Psi_{*}^{x}e^{O_{1}R_{x}}(xL_{3,n}+x^{-2}R_{x}).\label{J-1-bound-final}
\end{align}
And for $J_{2}$, since,
\begin{align}
  &\int_{0}^{+\infty}e^{-\lambda_{1}\sigma_nt}\,d\Phi(t) =  \frac{e^{\lambda_{1}^{2}\sigma_{n}^{2}/2}}{\sqrt{2\pi}}\int_{\lambda_{1}\sigma_{n}}^{\infty}e^{-t^2/2}\,dt =\frac{1}{\sqrt{2\pi}}\psi(\lambda_{1}\sigma_{n}),\notag
\end{align}
where $\psi(x) = \frac{1-\Phi(x)}{\Phi^{'}(x)} = e^{\frac{x^2}{2}}\int_{x}^{\infty}e^{-\frac{t^2}{2}}\,dt$. Following that for $x>1$,%实际上x>0都成立。
\begin{align}
  \frac{x}{1+x^2}e^{-\frac{x^2}{2}}\leq \int_{x}^{\infty}e^{-\frac{t^2}{2}}\,dt\leq \frac{1}{x}e^{-\frac{x^2}{2}},\label{int-exp(-x^2/2)-bound}
\end{align}
we have,
\begin{align}
  \frac{x}{1+x^2} \leq \psi(x) \leq  \frac{1}{x} \quad \text{and} \quad 0<-\psi^{\prime}(x) = 1-xe^{\frac{x^2}{2}}\int_{x}^{\infty}e^{-\frac{t^2}{2}}\,dt\leq \frac{1}{1+x^2},\label{psi-property}
\end{align}
by (\ref{mlambda1+x^2/2-lambda1x^2}), (\ref{exp(-x^2/2)-leq-1-phi-bound}), (\ref{int-exp(-x^2/2)-bound}) and (\ref{psi-property}) we can have,
\begin{align}
  J_2 = & \exp(m(\lambda_1)-\lambda_1x^2)\int_{0}^{+\infty}e^{-\lambda_{1}\sigma_{n}t}\,d\Phi(t)\notag\\
  \leq &\Psi^{*}_{x}e^{O_{1}R_x}e^{-\frac{x^2}{2}}\frac{1}{\sqrt{2\pi}}\left(\psi(2\lambda_{1}x)+|\psi(\lambda_{1}\sigma_n)-\psi(2\lambda_{1}x)|\right)\notag\\
  \leq & \Psi^{*}_{x}e^{O_{1}R_x}e^{-\frac{x^2}{2}}\psi(2\lambda_{1}x)\left(1+\frac{\psi^{\prime}(\theta)}{\psi(2\lambda_{1}x)}|\lambda_{1}\sigma_{n}-2\lambda_{1}x|\right)\notag\\
  \leq &[1-\Phi(x)]\Psi^{*}_{x}e^{O_{1}R_x}(1+3x^{-1}|\lambda_{1}\sigma_{n}-2\lambda_{1}x|),\label{J-2-bound-middle}
\end{align}
since (\ref{sigma_n}), we have
\begin{align}
  &|\lambda_{1}\sigma_{n}-2\lambda_{1}x|\notag\\
  = & \frac{\lambda_{1}|\sigma_n^2-4x^2|}{\sigma_n+2x}\notag\\
  = & \frac{\lambda_{1}|x^3(8\lambda_{1}\sum_{i=1}^{n}EX_i^3-4\sum_{i=1}^{n}EX_iY_i^2)+O_2R_x|}{\sigma_n+2x}\notag\\
  \leq & A(x^2L_{3,n}+x^{-1}R_x),
\end{align}
so we can have,
\begin{align}
  J_2 \leq [1-\Phi(x)]\Psi^{*}_{x}e^{O_{1}R_x}(1+xL^{3,n}+x^{-2}R_{x}).\label{J-2-bound-final}
\end{align}
Combine (\ref{J-1-bound-final}) and (\ref{J-2-bound-final}), we have
\begin{equation}
  H_1 = J_1+J_2 \leq [1-\Phi(x)]\Psi^{*}_{x}e^{O_{1}R_x}(1+O_{2}xL_{3,n}).\label{H-1-bound-final}
\end{equation}
Next we find an upper bound of $H_2$, by (\ref{mlambda1+x^2/2-lambda1x^2})
\begin{align}
  H_2 = & \exp(m(\lambda_1)-\lambda_1m_n)\mathbb{E} \left(e^{-\lambda_1\sigma_n U_n}{\bf 1}\{0\geq U_n\geq -\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\}\right)\notag\\
  \leq &\Psi^{*}_{x}e^{O_{1}R_x}e^{-\frac{x^2}{2}}\mathbb{E} \left(e^{-\lambda_{1}\sigma_{n}U_n}{\bf 1}\{0\geq U_n\geq -\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\}\right)
\end{align}
since $x\tilde{\Delta}_{1,n}\leq 1$, We have
\begin{align}
  &\mathbb{E} \left(e^{-\lambda_{1}\sigma_{n}U_n}{\bf 1}\{0\geq U_n \geq -\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\}\right)\notag\\
  \leq &\mathbb{E}\left(e^{\lambda_{1}2x\tilde{\Delta}_{1n}}{\bf 1}\{0\geq U_n-\epsilon_n\geq-\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\}\right)\notag\\
  \leq&e^{2}P\left(-\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\leq U_n\leq 0\right)
\end{align}
By applying the randomize concentration inequality by \cite{shao2016cramer},
\begin{align}
  &P\left(-\frac{2x\tilde{\Delta}_{1n}}{\sigma_n}\leq U_n\leq 0\right) \leq 17\nu_n\sigma_{n}^{-3}+5x\sigma_{n}^{-1}\mathbb{E}|\tilde{\Delta}_{1n}|+ 2x\sigma_n^{-2}\sum_{i=1}^{n}E|\tilde{W_i}(\tilde{\Delta}_{1n}-\tilde{\Delta}_{1n}^{(i)})|
\end{align}
where $\tilde{\Delta}_{1n}^{(i)}$ can be any random variable that is independent of $\tilde{W}_{i}$. By (\ref{Un-berry-esseen-bound}) we know that
\begin{align}
  \nu_{n}\sigma_{n}^{-3}\leq A(L_{3,n}+x^{-3}R_x).\notag
\end{align}
For the other two tems, by change of measure, the distribution of $(\xi_{i},\eta_{i})$ defined in (\ref{change-of-measure-distribution}), we have
\begin{align}
  E|\tilde{\Delta}_{1n}| = & \int\dots\int|\Delta_{1n}(x_1,\dots,x_n,y_1,\dots,y_n)|dV_1(x_1,y_1)\dots dV_n(x_n,y_n)\notag\\
  = &(\mathbb{E} e^{\lambda_{1}\sum_{i=1}^{n}W_i})^{-1}\int\dots\int|\Delta_{1n}(x_1,\dots,x_n,y_1,\dots,y_n)|\prod_{i=1}^{n}\{e^{\lambda_{1}W_i}\,dF_{(X_i,Y_i)}(x_i,y_i)\}\notag\\
  =&\exp\{-m(\lambda_{1})\}\mathbb{E}\left(|\Delta_{1n}|e^{\lambda_{1}\sum_{i=1}^{n}W_i}\right),
\end{align}
similarly we can also have,
\begin{align}
  E|\tilde{W_i}(\tilde{\Delta}_{1n}-\tilde{\Delta}_{1n}^{(i)})| = \exp\{-m(\lambda_{1})\}E(|W_i(\Delta_{1n}-\Delta_{1n}^{(i)})|e^{\lambda_{1}\sum_{j=1}^{n}W_j})
\end{align}
since $\Delta_{1n} = min\{x(V_n^2-1)^2+|D_{1n}|-x\min(D_{2n},0),1/x\}$, we have
\begin{align}
  dd
\end{align}
$$|\Delta_{1,n}-\Delta_{1,n}^{(i)}|\leq x((V_n^2-1)^2-\{(V_n^2-1)^2\}^{(i)})+|D_{1,n}-D_{1,n}^{(i)}|+x|D_{2,n}-D_{2,n}^{(i)}|$$
$$|\Delta_{1,n}|\leq x(V_n^2-1)^2+|D_{1,n}|+x|D_{2,n}|$$ and $$V_n^2-1 = \sum_{i=1}^{n}Y_i^2-\sum_{i=1}^{n}EY_i^2 = \sum_{i=1}^{n}Z_i$$ $$(V_n^2-1)^2-((V_n^2-1)^{2})^{(i)} = Z_i^2+2Z_i\sum_{j\neq i}Z_j,$$ by lemma3 we have
$$E((V_n^2-1)e^{\lambda\sum_{j=1}^{n}W_j})\leq A_1\Psi^{*}_{x}e^{AR_x} x^{-2}R_x$$
$$\sum_{i=1}^{n}E(|W_i||Z_i^2+2Z_i\sum_{j\neq i}Z_j|e^{\lambda\sum_{j=1}^{n}W_j})\leq A_1\Psi^{*}_{x}e^{AR_x} x^{-2}R_x$$
so
\begin{equation}
  \begin{aligned}
    H_2 \leq & A\Psi_{x}^{*}e^{AR_x}e^{-\frac{x^2}{2}}(L_{3,n}+x^{-3}R_x+\frac{x}{\sigma_n}(\Psi_{*}^{x}e^{AR_x})^{-1}\mathbb{E}\left(|\Delta_{1,n}|e^{\frac{1}{2}\sum_{i=1}^{n}W_i}\right)\\
    & +\frac{x}{\sigma_n^2}(\Psi_{*}^{x}e^{AR_x})^{-1}\sum_{i=1}^{n}E(|W_i(\Delta_{1,n}-\Delta_{1,n}^{(i)})|e^{\frac{1}{2} \sum_{j=1}^{n}W_j}))\\
    \leq&A\Psi_{x}^{*}e^{AR_x}e^{-\frac{x^2}{2}}(L_{3,n}+x^{-3}R_x+\frac{x^2}{\sigma_n}(\Psi_{x}^{*}e^{AR_x})^{-1}\mathbb{E}\left((V_n^2-1)^2e^{\frac{1}{2}\sum_{i=1}^{n}W_i}\right)\\
    &+\frac{x}{\sigma_n}(\Psi_{x}^{*}e^{AR_x})^{-1}\mathbb{E}((|D_{1,n}|+x|D_{2,n}|)e^{\frac{1}{2}\sum_{i=1}^{n}W_i})\\
    &+\frac{x^2}{\sigma_n^2}(\Psi_{x}^{*}e^{AR_x})^{-1}\sum_{i=1}^{n}\mathbb{E}(|W_i||Z_i^2+2Z_i\sum_{j\neq i}|e^{\frac{1}{2}\sum_{j=1}^{n}W_j})\\
    &+ \frac{x}{\sigma_n^2}(\Psi_{x}^{*}e^{AR_x})^{-1}\sum_{i=1}^{n}\mathbb{E}(|W_i(|D_{1,n}-D_{1,n}^{(i)}|+x|D_{2,n}-D_{2,n}^{(i)}|)|e^{\frac{1}{2}\sum_{j=1}^{n}W_j}))\\
    \leq &A\Psi_{x}^{*}e^{AR_x}e^{-\frac{x^2}{2}}(L_{3,n}+x^{-3}R_x+x^{-1}R_x+x^{-2}R_x+\\
    &+\frac{x}{\sigma_n}(\Psi_{x}^{*}e^{AR_x})^{-1}\mathbb{E}((|D_{1,n}|+x|D_{2,n}|)e^{\frac{1}{2}\sum_{i=1}^{n}W_i})\\
    &+\frac{x}{\sigma_n^2}(\Psi_{x}^{*}e^{AR_x})^{-1}\sum_{i=1}^{n}\mathbb{E}(|W_i(|D_{1,n}-D_{1,n}^{(i)}|+x|D_{2,n}-D_{2,n}^{(i)}|)|e^{\frac{1}{2}\sum_{j=1}^{n}W_j}))\\
  \end{aligned}
\end{equation}
Since for $x>0$ we have $[1-\Phi(x)]\sim\frac{1}{x}e^{-\frac{x^2}{2}}$, we have $e^{\frac{x^2}{2}}[1-\Phi(x)]\geq Ax^{-1}$
\begin{equation}
  \begin{aligned}
    H_2 \leq & A\Psi_{x}^{*}e^{AR_x}e^{-\frac{x^2}{2}}[1-\Phi(x)]e^{\frac{x^2}{2}}(xL_{3,n}+x^{-2}R_x+R_x+x^{-1}R_x+Q_{n,x})\\
    \leq & A\Psi_{x}^{*}e^{AR_x}[1-\Phi(x)](xL_{3,n}+Q_{n,x})
  \end{aligned}
\end{equation}
Where
\begin{equation}
  \begin{aligned}
    Q_{n,x} =& (\Psi_{x}^{*}e^{AR_x})^{-1}\mathbb{E}((x|D_{1,n}|+x^2|D_{2,n}|)e^{\frac{1}{2}\sum_{i=1}^{n}W_i})\\
            &+(\Psi_{x}^{*}e^{AR_x})^{-1}\sum_{i=1}^{n}\mathbb{E}(|W_i(|D_{1,n}-D_{1,n}^{(i)}|+x|D_{2,n}-D_{2,n}^{(i)}|)|e^{\frac{1}{2}\sum_{j=1}^{n}W_j})\\
  \end{aligned}
\end{equation}
combine with $$H_1\leq A\Psi_{x}^{*}e^{AR_x}[1-\Phi(x)](1+A_2xL_{3,n}+A_3x^{-2}R_x)$$
so we have
\begin{equation}
  \begin{aligned}
    &P(2xS_n-x^2V_n^2\geq x^2-2x\Delta_{1,n})\\
    =& H_1+H_2\\
    \leq & \Psi_{x}^{*}[1-\Phi(x)]e^{A_1R_x}(1+A_2(1+x)L_{3,n}+A_3Q_{n,x})
  \end{aligned}
\end{equation}
so we finish the proof of proposition1.




\end{proof}


% \begin{lem}
%   for $x$ satisfying $(14)$ and $(15)$, there exists an absolute constant A such that for $x>2$,
%   $$\mathbb{E} \{(V_n^2-1)^2e^{\frac{1}{2}\sum_{i=1}^{n}W_i}\}\leq A_1\Psi_{x}^{*}e^{AR_x}x^{-2}R_x$$
%   $$\sum_{i=1}^{n}\mathbb{E} \{|W_i||Z_i^2+2Z_i\sum_{j\neq i}Z_j|e^{\frac{1}{2}\sum_{i}^{n}W_i}\}\leq A_1\Psi_{x}^{*}e^{-AR_x}x^{-2}R_x$$
% \end{lem}


\begin{proof} Proof of proposition1
  
\end{proof}


\begin{proof} Proof of proposition2
  \begin{equation}
    \begin{aligned}
      &P(S_n\geq (x-1/2x)V_n,|V_{n}^{2}-1|>1/2x)\\
      =&P(S_n/V_n\geq x-1/2x,(1+1/2x)^{\frac{1}{2}}\leq V_n\leq B)\\
      &+P(S_n/V_n\geq x-1/2x,V_n>B)\\
      &+P(S_n/V_n\geq x-1/2x,V_n<(1-1/2x)^{\frac{1}{2}})\\
      =&\sum_{i=1}^{3}P((W_n,V_n)\in\varepsilon_n)
    \end{aligned}
  \end{equation}
  Where
  \begin{equation}
    \begin{aligned}
      &\varepsilon_1 = \{(u,v)\in\mathbb{R}*\mathbb{R^+}:\frac{u}{v}\geq x-\frac{1}{2x},\sqrt{1+\frac{1}{2x}}<v<B \}\\
      &\varepsilon_2 = \{(u,v)\in\mathbb{R}*\mathbb{R^+}:\frac{u}{v}\geq x-\frac{1}{2x},v<\sqrt{1-\frac{1}{2x}} \}\\
      &\varepsilon_3 = \{(u,v)\in\mathbb{R}*\mathbb{R^+}:\frac{u}{v}\geq x-\frac{1}{2x},v>B \}\\
    \end{aligned}
  \end{equation}
  by chebyshev inequality
  $$P((S_n,V_n)\in\varepsilon_1)\leq x^2\exp\{-\inf_{(u,v)\in\varepsilon_1}(t_1u-\lambda_1v^2)\}\mathbb{E}((V_n^2-1)^2\exp\{t_1S_n-\lambda_1V_n^2\})$$
  in lemma3 we have know that
  when $0<r<r_0<1$ for a constant $r_0$ and for a number $w>r_0$, there exits a $A_1$ and $A_2$ depending on $w$ and $r_0$ such that
  \begin{equation}
    \begin{aligned}
      &\mathbb{E}\left((V_n^2-1)^2e^{\sum_{i=1}^{n}(2rxX_i-wrx^2Y_i^2)}\right)\\
      \leq& \frac{A_1R_x}{x^2}\exp\{(2r^2-wr)x^2-2wr^2x^3\sum_{i=1}^{n}\mathbb{E} X_iY_i^2+\frac{4}{3}r^3x^3\sum_{i=1}^{n}\mathbb{E} X_i^3+A_2R_x\}
    \end{aligned}
  \end{equation}
  in this case we have
  \begin{equation}
    \begin{aligned}
      &\mathbb{E} \left((V_n^2-1)^2e^{\sum_{i=1}^{n}(t_1X_i-\lambda_1Y_i^2)}\right)\\
      \leq & \frac{A_2R_x}{x^2}\exp\{\frac{t_1^2}{2}-\lambda_1+\frac{t_1^3}{6}\sum_{i=1}^{n}\mathbb{E} X_i^3-\lambda_1t_1\sum_{i=1}^{n}\mathbb{E} X_iY_i^2+A_2R_x\}
    \end{aligned}
  \end{equation}
  so we have
  \begin{equation}
    \begin{aligned}
      &P((S_n,V_n)\in\varepsilon_1)\\
      \leq &A_1R_x\exp\{-\inf_{(u,v)\in\varepsilon_1}(t_1u-\lambda_1v^2)\}\exp\{\frac{t_1^2}{2}-\lambda_1+\frac{t_1^3}{6}\sum_{i=1}^{n}\mathbb{E} X_i^3-\lambda_1t_1\sum_{i=1}^{n}\mathbb{E} X_iY_i^2+A_2R_x\}\\
    \end{aligned}
  \end{equation}
  now we choose $t_1 = x\sqrt{1+\frac{1}{2x}}$ and $\lambda_1 = t_1(x-\frac{1}{2x})/8$, and since $B = \max\{50,200c_0\}$, then we have $$\inf_{(u,v)\in\varepsilon_1}(t_1u-\lambda_1v^2) = x^2+\frac{x}{2}-\lambda_1(1+\frac{1}{2x})-\frac{1}{2}-\frac{1}{4x}$$
  so we have,
  \begin{equation}
    \begin{aligned}
      P((S_n,V_n)\in\varepsilon_1)\leq &AR_x\exp\{-x^2-\frac{x}{2}+\frac{x\sqrt{1+\frac{1}{2x}}(x-\frac{1}{2x})(1+\frac{1}{2x})}{8}+\frac{1}{2}+\frac{1}{4x}\}\\
      &*\exp\{\frac{x^2(1+\frac{1}{2x})}{2}-\frac{x\sqrt{1+\frac{1}{2x}}(x-\frac{1}{2x})}{8}+\frac{x^3(1+\frac{1}{2x})^{\frac{3}{2}}}{6}\sum_{i=1}^{n}\mathbb{E} X_i^3\\
      &-\frac{x^2(1+\frac{1}{2x})(x-\frac{1}{2x})}{8}\sum_{i=1}^{n}\mathbb{E} X_iY_i^2+ A_2R_x\}\\
      \leq &AR_xe^{A_2R_x}\exp\{-\frac{x^2}{2}\}\exp\{\frac{x^3}{6}\sum_{i=1}^{n}\mathbb{E} X_iY_i^3-\frac{x^3}{8}\sum_{i=1}^{n}\mathbb{E} X_iY_i^2\}\\
      \lesssim & AR_xe^{A_2R_x}[1-\Phi(x)]\Psi_{x}^{*}
    \end{aligned}
  \end{equation}
  as for $$P((S_n,V_n)\in\varepsilon_2)\leq x^2\exp\{-\inf_{(u,v)\in\varepsilon_2}(t_2u-\lambda_2v^2)\}\mathbb{E} \left((V_n^2-1)^2e^{t_2S_n-\lambda_2V_n^2}\right)$$
  now we choose $t_2 = x\sqrt{1-\frac{1}{2x}}$ and $\lambda_2 = 2x^2-1$ and since $B = \max\{50,200c_0\}$,
  $$\inf_{(u,v)\in\varepsilon_2}(t_2u-\lambda_2v^2) = x^2-\frac{x}{2}-\frac{1}{2}+\frac{1}{4x}-(2x^2-1)(1-\frac{1}{2x})$$
  so
  \begin{equation}
    \begin{aligned}
      P((S_n,V_n)\in\varepsilon_2)\leq &x^2\exp\{-x^2+\frac{x}{2}+\frac{1}{2}-\frac{1}{4x}+(2x^2-1)(1-\frac{1}{2x})\}\\
      &\frac{A_2R_x}{x^2}\exp\{\frac{t_2^2}{2}-\lambda_2+\frac{t_2^3}{6}\sum_{i=1}^{n}\mathbb{E} X_i^3-\lambda_2t_2\sum_{i=1}^{n}\mathbb{E} X_iY_i^2+A_2R_x\}\\
      \leq & AR_xe^{A_2R_x}\exp\{-\frac{x^2}{2}\}\Psi_{x}^{*}\\
      \lesssim& AR_xe^{A_2R_x}[1-\Phi(x)]\Psi_{x}^{*}\\
    \end{aligned}
  \end{equation}
  as for 
  \begin{equation}
    \begin{aligned}
      &P((S_n,V_n)\in\varepsilon_3)\\
      =& P(\frac{S_n}{V_n}>x-\frac{1}{2x},V_n>B)\\
      \leq & P(S_n^{in}>\frac{V_n}{10}(x-\frac{1}{2x}),V_n>B)+P(S_n^{out}>\frac{9V_n}{10}(x-\frac{1}{2x}),V_n>B)\\
      \leq &P(S_n^{in}>\frac{B}{10}(x-\frac{1}{2x}),V_n^{in}>\frac{B}{2})+P(S_n^{in}>\frac{B}{10}(x-\frac{1}{2x}),V_n^{out}>\frac{B}{2})\\
      &P(S_n^{out}>\frac{9V_n}{10}(x-\frac{1}{2x}),V_n>B)\\
      :=& K_1+K_2+K_3\\
    \end{aligned}
  \end{equation}
  where 
  \begin{equation}
    \begin{aligned}
      &X_i^{in} = X_i1\{|(1+x)X_i|\leq 1\}\ \ X_i^{out} = X_i1\{|(1+x)X_i|> 1\}\\
      &Y_i^{in} = X_i1\{|(1+x)X_i|\leq 1\}\ \ Y_i^{out} = X_i1\{|(1+x)X_i|> 1\}\\
      & S_n^{in} = \sum_{i = 1}^{n}X_i^{in}, S_n^{out} = \sum_{i =1}^{n}X_i^{out}\\
      & V_n^{in} = \sqrt{\sum_{i=1}^{n}(Y_{i}^{in})^2},V_n^{out} = \sqrt{\sum_{i=1}^{n}(Y_{i}^{out})^2}\\
    \end{aligned}
  \end{equation}
  \begin{equation}
    \begin{aligned}
      K_1 & = P(S_n^{in}>\frac{B}{10}(x-\frac{1}{2x}),V_n^{in}>\frac{B}{2})\\
      &\leq \frac{\mathbb{E} \{((V_n^{in})^2-1)^2e^{\frac{xS_n^{in}}{2}}\}\exp\{-\frac{B}{20}x^2+\frac{B}{40}\}}{(\frac{B^2}{4}-1)^2}
    \end{aligned}
  \end{equation}
  we let $Z_{i}^{in} = (Y_{i}^{in})^2=\mathbb{E} (Y_{i}^{in})^2$ then we have $(V_{i}^{in})^2-1 = \sum_{i=1}^{n}Z_{i}^{in}-\sum_{i=1}^{n}\mathbb{E} (Y_{i}^{out})^2$, so we have
  \begin{equation}
    \begin{aligned}
      \mathbb{E} \{((V_n^{in})^2-1)^2e^{\frac{xS_n^{in}}{2}}\}\leq& 2\sum_{i=1}^{n}\frac{\mathbb{E} (Z_i^{in})^2e^{\frac{xX_{i}^{in}}{2}}}{\mathbb{E} e^{\frac{xX_{i}^{in}}{2}}}\prod_{j = 1}^{n}\mathbb{E} e^{\frac{xX_{j}^{in}}{2}}+2x^{-4}R_x^2\prod_{j = 1}^{n}\mathbb{E} e^{\frac{xX_{j}^{in}}{2}}\\
      &+4\sum_{i\neq j}\frac{\mathbb{E} Z_i^{in}e^{\frac{xX_{i}^{in}}{2}}}{\mathbb{E} e^{\frac{xX_{i}^{in}}{2}}}\frac{\mathbb{E} Z_j^{in}e^{\frac{xX_{j}^{in}}{2}}}{\mathbb{E} e^{\frac{xX_{j}^{in}}{2}}}\prod_{j=1}^{n}\mathbb{E} e^{\frac{xX_{j}^{in}}{2}}
    \end{aligned}
  \end{equation}
  by taylor expansion we have
  $$\mathbb{E} e^{\frac{xX_i^{in}}{2}} = \exp\{\frac{1}{8}x^2\mathbb{E} X_i^2+\frac{1}{48}x^3\mathbb{E} X_i^3+O_1\delta_{x,i}\}$$
  $$\mathbb{E} (Z_i^{in})^2e^{\frac{xX_{i}^{in}}{2}} = O(x^{-4}\delta_{x,i})$$
  $$\mathbb{E} Z_i^{in}e^{\frac{xX_{i}^{in}}{2}} = O(x(\mathbb{E} |X_i|^3+\mathbb{E} |Y_i|^3))+O(x^-2\delta_{x,i})$$\
  $$\mathbb{E} (Y_i^{out})^2e^{\frac{xX_{i}^{in}}{2}} = O(x^{-2}\delta_{x,i})$$
  combining the fact that $x^4L_{3,n}^{2}\leq 4\delta_{x}$, we have
  $$\mathbb{E} \{((V_n^{in})^2-1)^2e^{\frac{xS_n^{in}}{2}}\}\leq \frac{AR_x}{x^2}\exp\{\frac{1}{8}x^2+\frac{1}{48}x^3\sum_{i=1}^{n}\mathbb{E} X_i^3+ A_1R_x\}$$
  so
  \begin{equation}
    \begin{aligned}
      K_1\leq& A(\frac{B^2}{4}-1)^{-2}x^{-2}R_x\exp\{(\frac{1}{8}-\frac{B}{20})x^2+\frac{B}{40}+\frac{1}{48}\sum_{i=1}^{n}\mathbb{E} X_i^3+A_1R_x\}\\
      \leq &C_1x^{-2}R_x\exp\{-\frac{19}{8}x^2+\frac{B}{40}+\frac{1}{48}\sum_{i=1}^{n}\mathbb{E} X_i^3+A_1R_x\}\\
      \leq &C_2R_x[1-\Phi(x)]\Psi_{x}^{*}e^{A_1R_x}
    \end{aligned}
  \end{equation}
  last inequality holds because x satisfies condition (2.6) and $$|x^3\sum_{i=1}^{n}\mathbb{E} X_i^3|\leq x^3 L_{x,n} \ \ and\ \  |x^3\sum_{i=1}^{n}\mathbb{E} X_iY_i^2|\leq x^3L_{3,n}$$
  similarly for $K_2$ er have
  \begin{equation}
    \begin{aligned}
      K_2 =& P(S_n^{in}>\frac{B}{10}(x-\frac{1}{2x}),V_n^{out}>\frac{B}{2})\\
      \leq &\frac{4\mathbb{E} \{(V_{n}^{out})^2e^{\frac{xS_{n}^{in}}{2}}\}\exp\{-\frac{B}{20}x^2+\frac{B}{40}\}}{B^2}
    \end{aligned}
  \end{equation}
  and
  \begin{equation}
    \begin{aligned}
      \mathbb{E} \{(V_{n}^{out})^2e^{\frac{xS_{n}^{in}}{2}}\} & = \sum_{i=1}^{n}\frac{\mathbb{E} (Y_i^{out})^2e^{\frac{xX_{i}^{in}}{2}}}{\mathbb{E} e^{\frac{xX_{i}^{in}}{2}}}\prod_{i=j}^{n}\mathbb{E} e^{\frac{xX_{j}^{in}}{2}}\\
      &\leq \frac{AR_x}{x^2}\exp\{\frac{1}{8}x^2+\frac{1}{48}x^3\sum_{i=1}^{n}\mathbb{E} X_i^3+A_1R_x\}
    \end{aligned}
  \end{equation}
  hence
  \begin{equation}
    \begin{aligned}
      K_2\leq 4AB^{-2}x^{-2}R_x\exp\{(\frac{1}{8}-\frac{B}{20})x^2+\frac{B}{40}+\frac{1}{48}\sum_{i=1}^{n}\mathbb{E} X_i^3+A_1R_x\}
    \end{aligned}
  \end{equation}
  in the same manner of proof of $K_1$, it follows that,
  $$K_2 \leq AR_x[1-\Phi(x)]\Psi_{x}^{*}e^{A_1R_x}$$
  as for $K_3$ we denote that
  $$X_{i}^{out(1)} = X_i1\{2xX_i\leq \frac{X_i^2}{Y_i^2+c_0\mathbb{E} Y_i^2}\},\ \ X_{i}^{out(2)} = X_{i}^{out}-X_{i}^{out(1)}$$
  $$S_{n}^{out(1)} = \sum_{i=1}^{n}X_{i}^{out(1)}, \ \ S_{n}^{out(2)} = \sum_{i=1}^{n}X_{i}^{out(2)}$$
  so we have 
  \begin{equation}
    \begin{aligned}
      K_3 =& P(S_n^{out}>\frac{9V_n}{10}(x-\frac{1}{2x}),V_n>B)\\
      \leq & P(S_n^{out(1)}>\frac{1V_n}{100}(x-\frac{1}{2x}),V_n>B)\\
      & + P(S_n^{out(2)}>\frac{89V_n}{100}(x-\frac{1}{2x}),V_n>B)\\
      \leq & P(\sum_{i=1}^{n}2xX_{i}^{out(1)}>\frac{V_n}{50}(x^2-\frac{1}{2}),V_n>B)\\
      &+P(\sqrt{\sum_{i=1}^{n}\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}}>\frac{89V_n(x-\frac{1}{2x})}{100\sqrt{V_n^2+c_0}},V_n>B)\\
      :=&K_4+K_5
    \end{aligned}
  \end{equation}
  since $$\prod_{j\neq i}\mathbb{E} e^{2xX_{j}^{out(1)}}\leq \exp\{R_x\}$$
  $$\prod_{j\neq i}\mathbb{E} e^{\frac{(X_{j}^{out(2)})^2}{Y_j^2+c_0\mathbb{E} Y_{j}^{2}}}\leq \exp\{R_x\}$$
  $$R_x\geq \sum_{i=1}^{n}\mathbb{E} [e^{2xX_{i}^{out(1)}}]+\sum_{i=1}^{n}\mathbb{E} [e^{\frac{(X_{i}^{out(2)})^2}{Y_i^2+c_0\mathbb{E} Y_i^2}}]$$
  then we choose $B = \max\{50,200c_0\}$ then we have for $x>c>2$
  \begin{equation}
    \begin{aligned}
      &P(\sum_{i=1}^{n}2xX_{i}^{out(1)}>\frac{V_n}{50}(x^2-\frac{1}{2}),V_n>B)\\
      \leq &P(\sum_{i=1}^{n}2xX_{i}^{out(1)}>x^2-1/2)\\
      \leq &(x^2-1/2)^{-1}\exp\{-0.99(x^2-1/2)\}\mathbb{E} [\sum_{I=1}^{n}2xX_{i}^{out(1)}e^{0.99\sum_{i=1}^{n}2xX_{i}^{out(1)}}]\\
      \leq &C_2x^{-2}\exp\{-0.99x^2\}\sum_{i=1}^{n}\mathbb{E} [e^{2xX_{i}^{out(1)}}]\prod_{j\neq i}\mathbb{E} e^{2xX_{j}^{out(1)}}\\
      \leq &AR_x[1-\Phi(x)]\Psi_{x}^{*}\exp\{R_x\}
    \end{aligned}
  \end{equation}
  \begin{eqnarray}
    \begin{aligned}
      &P(\sqrt{\sum_{i=1}^{n}\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}}>\frac{89V_n(x-\frac{1}{2x})}{100\sqrt{V_n^2+c_0}},V_n>B)\\
      \leq &P(\sum_{i=1}^{n}\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}>0.792(x-\frac{1}{2x})^2)\\
      \leq &P(\sum_{i=1}^{n}\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}>0.6x^2)\\
      \leq & C_1x^{-2}\exp\{-0.54x^2\}\mathbb{E} [\sum_{i=1}^{n}\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}e^{0.99\sum_{i=1}^{n}\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}}]\\
      \leq & C_2x^{-2}\exp\{-0.54x^2\}\sum_{i=1}^{n}\mathbb{E} [e^{\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}}]\prod_{j\neq i}\mathbb{E} e^{\frac{(X_{i}^{out(2)})^{2}}{Y_i^2+c_0\mathbb{E} Y_i^2}}\\
      \leq & AR_x[1-\Phi(x)]\Psi_{x}^{*}\exp\{R_x\}\\
    \end{aligned}
  \end{eqnarray}
  combine that we have
  \begin{equation}
    P(S_n\geq(x-\frac{1}{2x})V_n,|V_n^2-1|>\frac{1}{2x})\leq AR_x[1-\Phi(x)]\Psi_{x}^{*}e^{AR_x}
  \end{equation}
\end{proof}


\begin{proof} Proof of proposition3

  we also use change of measure
  \begin{equation}
    \begin{aligned}
      &P(xS_n-x^2V_{n}^{2}/2\geq x^2/2+x\Delta_{2n})\\
      =&P(\sum_{i=1}^{n}(2xX_i-x^2Y_i^2)\geq x^2+2x\Delta_{2,n})\\
      =&\Psi_{x}^{*}e^{AR_x}\mathbb{E} [e^{-\frac{1}{2}\sigma_nU_n-\frac{1}{2}m_n}1\{U_n\geq \epsilon_n+\frac{2x\tilde{\Delta}_{2,n}}{\sigma_n}\}]\\
      \geq &\Psi_{x}^{*}e^{AR_x}\mathbb{E} [e^{-\frac{1}{2}\sigma_nU_n-\frac{1}{2}m_n}1\{U_n\geq \epsilon_n\}]\\
      &+\Psi_{x}^{*}e^{AR_x}\mathbb{E} [e^{-\frac{1}{2}\sigma_nU_n-\frac{1}{2}m_n}1\{\epsilon \leq U_n\leq \epsilon_n+\frac{2x\tilde{\Delta}_{2,n}}{\sigma_n}\}]\\
      :=& H_1^{'}-H_{2}^{'}
    \end{aligned}
  \end{equation}
  similarly with the proof of proposition1 $H_{1}^{'} = J_{1}^{'}+J_{2}^{'}$, we drop $J_{1}^{'}$ and 
  \begin{equation}
    \begin{aligned}
      J_{2}^{'}&\geq \Psi_{x}^{*}e^{AR_x}e^{-\frac{1}{2}x^2}\frac{1}{\sqrt{2}}\Psi(x)\\
      &\geq \Psi_{x}^{*}e^{AR_x}[1-\Phi(x)]\\
    \end{aligned}
  \end{equation}
  \begin{equation}
    \begin{aligned}
      H_{2}^{'}\leq [1-\Phi(x)]\Psi_{x}^{*}e^{AR_x}(1+O_1xL_{3,n}+O_2R_x+O_3Q_{n,x})
    \end{aligned}
  \end{equation}
  so we have 
  $$P(xS_n-x^2V_{n}^{2}/2\geq x^2/2+x\Delta_{2n})\geq \Psi_{x}^{*}e^{-A_2R_x}[1-\Phi(x)](1-O_2(1+x)L_{3,n}-O_3Q_{n,x})$$
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Main text entry area:


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Single Appendix:                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{appendix}
%\section*{???}%% if no title is needed, leave empty \section*{}.
%\end{appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Multiple Appendixes:                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{appendix}
%\section{???}
%
%\section{???}
%
%\end{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Support information, if any,             %%
%% should be provided in the                %%
%% Acknowledgements section.                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{acks}[Acknowledgments]
% The authors would like to thank ...
%\end{acks}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Funding information, if any,             %%
%% should be provided in the                %%
%% funding section.                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{funding}
% The first author was supported by ...
%
% The second author was supported in part by ...
%\end{funding}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Supplementary Material, including data   %%
%% sets and code, should be provided in     %%
%% {supplement} environment with title      %%
%% and short description. It cannot be      %%
%% available exclusively as external link.  %%
%% All Supplementary Material must be       %%
%% available to the reader on Project       %%
%% Euclid with the published article.       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{supplement}
%\stitle{???}
%\sdescription{???.}
%\end{supplement}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  imsart-???.bst  will be used to                        %%
%%  create a .BBL file for submission.                     %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%  MR numbers will be added by VTeX.                      %%
%%                                                         %%
%%  Use \cite{...} to cite references in text.             %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% if your bibliography is in bibtex format, uncomment commands:
%\bibliographystyle{imsart-nameyear} % Style BST file (imsart-number.bst or imsart-nameyear.bst)
%\bibliography{bibliography}       % Bibliography file (usually '*.bib')
\bibliographystyle{apalike}
\bibliography{refs.bib}
%% or include bibliography directly:
% \begin{thebibliography}{}
% \bibitem[\protect\citeauthoryear{???}{???}]{b1}
% \end{thebibliography}

\end{document}
